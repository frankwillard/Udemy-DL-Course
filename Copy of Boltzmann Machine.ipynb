{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Boltzmann Machine.ipynb","provenance":[{"file_id":"1JxIEe_TAcz-utfLKTqjbo3foOtqDGD0s","timestamp":1625326584309}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"K4f4JG1gdKqj"},"source":["#Boltzmann Machine"]},{"cell_type":"markdown","metadata":{"id":"1jbiqOK7dLGG"},"source":["##Downloading the dataset"]},{"cell_type":"markdown","metadata":{"id":"XL5MEkLcfRD2"},"source":["###ML-100K"]},{"cell_type":"code","metadata":{"id":"rjOPzue7FCXJ","colab":{"base_uri":"https://localhost:8080/","height":646},"executionInfo":{"status":"ok","timestamp":1591629496532,"user_tz":-330,"elapsed":17382,"user":{"displayName":"Nirav Agarwal (RA1811003010570)","photoUrl":"","userId":"01096445040044781974"}},"outputId":"44d3a628-f522-4d0d-efdf-009b7d3a28df"},"source":["!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n","!unzip ml-100k.zip\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-06-08 15:18:04--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4924029 (4.7M) [application/zip]\n","Saving to: ‘ml-100k.zip’\n","\n","\rml-100k.zip           0%[                    ]       0  --.-KB/s               \rml-100k.zip          18%[==>                 ] 884.39K  3.96MB/s               \rml-100k.zip         100%[===================>]   4.70M  15.6MB/s    in 0.3s    \n","\n","2020-06-08 15:18:04 (15.6 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n","\n","Archive:  ml-100k.zip\n","   creating: ml-100k/\n","  inflating: ml-100k/allbut.pl       \n","  inflating: ml-100k/mku.sh          \n","  inflating: ml-100k/README          \n","  inflating: ml-100k/u.data          \n","  inflating: ml-100k/u.genre         \n","  inflating: ml-100k/u.info          \n","  inflating: ml-100k/u.item          \n","  inflating: ml-100k/u.occupation    \n","  inflating: ml-100k/u.user          \n","  inflating: ml-100k/u1.base         \n","  inflating: ml-100k/u1.test         \n","  inflating: ml-100k/u2.base         \n","  inflating: ml-100k/u2.test         \n","  inflating: ml-100k/u3.base         \n","  inflating: ml-100k/u3.test         \n","  inflating: ml-100k/u4.base         \n","  inflating: ml-100k/u4.test         \n","  inflating: ml-100k/u5.base         \n","  inflating: ml-100k/u5.test         \n","  inflating: ml-100k/ua.base         \n","  inflating: ml-100k/ua.test         \n","  inflating: ml-100k/ub.base         \n","  inflating: ml-100k/ub.test         \n","ml-100k  ml-100k.zip  sample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9Xis6ldDfTs6"},"source":["###ML-1M"]},{"cell_type":"code","metadata":{"id":"LOly1yfAfTjd","colab":{"base_uri":"https://localhost:8080/","height":323},"executionInfo":{"status":"ok","timestamp":1591629505410,"user_tz":-330,"elapsed":26251,"user":{"displayName":"Nirav Agarwal (RA1811003010570)","photoUrl":"","userId":"01096445040044781974"}},"outputId":"22029b8c-79f2-46a2-a745-cdce83582b40"},"source":["!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n","!unzip ml-1m.zip\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-06-08 15:18:16--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5917549 (5.6M) [application/zip]\n","Saving to: ‘ml-1m.zip’\n","\n","ml-1m.zip           100%[===================>]   5.64M  2.44MB/s    in 2.3s    \n","\n","2020-06-08 15:18:19 (2.44 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n","\n","Archive:  ml-1m.zip\n","   creating: ml-1m/\n","  inflating: ml-1m/movies.dat        \n","  inflating: ml-1m/ratings.dat       \n","  inflating: ml-1m/README            \n","  inflating: ml-1m/users.dat         \n","ml-100k  ml-100k.zip  ml-1m  ml-1m.zip\tsample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EOBJ8UCXdY0g"},"source":["##Importing the libraries"]},{"cell_type":"code","metadata":{"id":"_LvGeU1CeCtg"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","#Parallel computations\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","#SGD\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pM04FyMudkoK"},"source":["## Importing the dataset\n"]},{"cell_type":"code","metadata":{"id":"UJw2p3-Cewo4"},"source":["#seperator is comma for csv, must use :: (some movies contain commas)\n","#no header (col names)\n","#engine- make sure data is imported correctly (python- efficient)\n","#some movies have special characters- use latin-1\n","\n","# We won't be using this dataset.\n","movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","#includes gender,age,job\n","users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","#Includes user IDs, movie IDs, ratings\n","ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTIbE2tkdkwP"},"source":["## Preparing the training set and the test set\n"]},{"cell_type":"code","metadata":{"id":"2usLKJBEgPE2"},"source":["#several 80% train/test splits in 100k folder (could perform K fold CV)\n","#delimiter is tab (for tab use delim not sep)\n","#need np arrays for pytorch tensors\n","training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n","#IDs and ratings- all integers\n","training_set = np.array(training_set, dtype = 'int')\n","test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n","test_set = np.array(test_set, dtype = 'int')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zCf8HjSydk4s"},"source":["## Getting the number of users and movies\n"]},{"cell_type":"code","metadata":{"id":"gPaGZqdniC5m"},"source":["#Plan\n","#going to make 2 matrices (1 train and test)\n","#same num users and movies\n","#each cell of index (user, movie) will get rating from user\n","#0 if not rating\n","\n","#User with highest ID or movie ID could be in either set- splits are random\n","#Get max of train and test and find max of those\n","\n","#i=0 is all users\n","nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n","#i=1 is all movies\n","nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J-w4-hVidlAm"},"source":["## Converting the data into an array with users in lines and movies in columns\n"]},{"cell_type":"code","metadata":{"id":"-wASs2YFiDaa"},"source":["#Corresponds to what RBM expects in input\n","#Create sturcture that will obtain observations in lines and features in columns\n","\n","def convert(data):\n","  #1 list per user in new_data\n","  new_data = []\n","  #for every user in dataset\n","  for id_users in range(1, nb_users + 1):\n","    #Gets movies and ratings for user\n","    #Full col of movies/ratings --> all movies/ratings for specific user\n","    id_movies = data[:, 1] [data[:, 0] == id_users]\n","    id_ratings = data[:, 2] [data[:, 0] == id_users]\n","    #Want 0s for unreviewed movies\n","    ratings = np.zeros(nb_movies)\n","    #Adds ratings to ratings np array\n","    #for rated movie, replace 0 with rating\n","    #id movies is indices of movies that were rated (movie start at 1 so subtract 1)\n","\n","    ratings[id_movies - 1] = id_ratings\n","    #Adds list of 1682 ratings of movies for user to new data np array\n","    new_data.append(list(ratings))\n","  return new_data\n","\n","#converted to array\n","training_set = convert(training_set)\n","test_set = convert(test_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AMmhuUpldlHo"},"source":["## Converting the data into Torch tensors\n"]},{"cell_type":"code","metadata":{"id":"TwD-KD8yiEEw"},"source":["#Tensors- multidimensional matrix with elements of certain datatype\n","#Tensors faster for NN\n","#Needs list of lists as input (why we converted data)\n","training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HIPruubGdlPW"},"source":["## Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)\n"]},{"cell_type":"code","metadata":{"id":"cslbPSh6iEka"},"source":["#Convert ratings (1-5) into binary\n","#Want to predict binary ratings- need inputs to match (will predict for non rated movies based on input)\n","\n","#If 0, -1 (not rated)\n","#If 1 or 2, 0 (didnt like)\n","#If 3-5, 1 (liked)\n","\n","training_set[training_set == 0] = -1\n","training_set[training_set == 1] = 0\n","training_set[training_set == 2] = 0\n","training_set[training_set >= 3] = 1\n","test_set[test_set == 0] = -1\n","test_set[test_set == 1] = 0\n","test_set[test_set == 2] = 0\n","test_set[test_set >= 3] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6kkL8NkkdlZj"},"source":["## Creating the architecture of the Neural Network\n"]},{"cell_type":"code","metadata":{"id":"oU2nyh76iE6M"},"source":["#Class is ensemble of instructions, model of something we want to build\n","\n","\n","class RBM():\n","  #initalize RBM object\n","  #define parameters of object that will be created once class is made\n","  #default compulsory function\n","  #self corresponds to object created, need it to attach variables to\n","  #nv- number of visible nodes, nh- number of hidden nodes\n","  def __init__(self, nv, nh):\n","    #weights- parameters of probabilities of visible nodes given hidden nodes\n","    #initialized in torch tensor of nh x nv (according to normal dist (u=0,sd=1))\n","    self.W = torch.randn(nh, nv)\n","    #bias for probabilities of hidden nodes given visible nodes\n","    #vector of nh elements\n","    #first dimension corresponds to batch, second corresponds to bias\n","    #(pytorch functions require two dimensional inputs with first being batcb, second bias)\n","    self.a = torch.randn(1, nh)\n","    #bias for probabilities of visible nodes given hidden nodes\n","    #vector of nv elements\n","    self.b = torch.randn(1, nv)\n","  #During sample- will approximate log likelihood gradient through Gibbs sampling\n","  #For Gibbs sampling, need probabilities of hidden nodes given visible\n","  #Can then sample activations of hidden nodes\n","  #Will activate each node according to certain prob P(H|V)\n","  #sample probabilities of hidden nodes given visible nodes\n","  #x is visible neurons\n","  def sample_h(self, x):\n","    #Compute product of neurons and weights (mm- product of two torch tensors)\n","    #Take transpose for consistent product\n","    wx = torch.mm(x, self.W.t())\n","    #Add bias a to wx\n","    #Apply bias to each line of minibatch (each line of 1 dimension)\n","    activation = wx + self.a.expand_as(wx)\n","    #Apply sigmoid activation function to wx+a\n","    p_h_given_v = torch.sigmoid(activation)\n","    #Some samples of hidden neurons according to probability\n","    #Bernoulli RBM as predicting binary outcome\n","    #Bernoulli samples of distribution\n","    #P(H|V) gas nh elements that has probs that correspond to hidden node (prob of activation)\n","    #Take random number and see if below probability threshold for each hidden node- activate if so\n","    #vector of 0s and 1s representing whetber node is activated\n","    return p_h_given_v, torch.bernoulli(p_h_given_v)\n","  #sample probabilities of visible nodes given hidden nodes\n","  #same as sample h\n","  def sample_v(self, y):\n","    wy = torch.mm(y, self.W)\n","    activation = wy + self.b.expand_as(wy)\n","    p_v_given_h = torch.sigmoid(activation)\n","    #predict activation - whether user likes given movie\n","    return p_v_given_h, torch.bernoulli(p_v_given_h)\n","  #use contrastive divergence- approximate rbm log likelihood gradient (try to max log likelihood)\n","  #direct computation of gradient too heavy - approximate\n","  #Gibbs sampling- sampling k times hidden and visible nodes (k step contrastive divergence)\n","  #start with input vector v0\n","  #based on probabilities ph, sample first set of nodes (first iter)\n","  #then take sampled hidden nodes as input (h1) with probs pv\n","  #then use sample visible nodes v1 to sample hidden nodes with probs p(h|V1)\n","  #sample again visible nodes and hidden nodes (k times)\n","  #v0- input vector, vk- visible nodes after k samplings (visible to hidden and back) k iter and k CD\n","  #ph0- vector of probs at first iter the hidden nodes=1 given V0\n","  #phk- probs after k samplings given vk\n","  def train(self, v0, vk, ph0, phk):\n","    #update tensor of weights w\n","    #add product of vj0 (rating of movie j) and p(h|v0)\n","    #subtract p(h|vk) * vjk (value of vis node corresp to movie j after k iterations)\n","    self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n","    #update bias p(v|h)\n","    #add vj0 - vjk\n","    #keep format as tensor of two dimensions\n","    self.b += torch.sum((v0 - vk), 0)\n","    #update bias p(h|v)\n","    #add ph0 - phk\n","    self.a += torch.sum((ph0 - phk), 0)\n","#visibles nodes- size is number of movies \n","#visible nodes are ratings of all movies by user\n","#could use nb movies\n","nv = len(training_set[0])\n","#100 hidden nodes- we choose\n","#features to detect- actors, oscars, genres\n","nh = 100\n","#will update weights after several observations (batch)\n","#makes training faster\n","batch_size = 100\n","rbm = RBM(nv, nh)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7gy59alAdloL"},"source":["## Training the RBM\n"]},{"cell_type":"code","metadata":{"id":"FEz9hRaciFTs","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1591629522316,"user_tz":-330,"elapsed":43116,"user":{"displayName":"Nirav Agarwal (RA1811003010570)","photoUrl":"","userId":"01096445040044781974"}},"outputId":"677ba886-38ee-43f2-9a2d-bed081429295"},"source":["nb_epoch = 10\n","#for each epoch, all observations will go into network\n","#will update weights after observations of each batch has passed through network\n","#end- will get final visible node with new ratings for unrated movies\n","for epoch in range(1, nb_epoch + 1):\n","  #loss function to measure error (pred ratings vs real)\n","  train_loss = 0\n","  #counter to normalize train loss\n","  #increment after each user\n","  s = 0.\n","  #loop over all users\n","  #step of batch size (0-99,100-199...)\n","  #stop at users - batch size as will add batch size\n","  for id_user in range(0, nb_users - batch_size, batch_size):\n","    #gets input and target (in batches)\n","    #input (vk) is ratings of all movies by user- will be out of Gibbs sampling\n","    #target is same (don't touch- use as comparison)\n","    #input will go through Gibbs sampling- will have new ratings\n","    vk = training_set[id_user : id_user + batch_size]\n","    v0 = training_set[id_user : id_user + batch_size]\n","    #initial probabilities P(H|V)\n","    #probs of H0 nodes = 1 given visible nodes at beginning\n","    #add underscore to not get bernoulli, only get probabilities (first arg)\n","    ph0,_ = rbm.sample_h(v0)\n","    #k steps of contrastive divergence\n","    #makes gibbs chain- several roudn trips from visible nodes to hidden nodes and vice versa\n","    #visible nodes updated each round- get closer to good pred ratings\n","    for k in range(10):\n","      #sample first hidden nodes with P(H|V)\n","      _,hk = rbm.sample_h(vk)\n","      #update vk to be sampled visible nodes after first step of gibbs sampling\n","      #sample based on sampling of hidden nodes\n","      _,vk = rbm.sample_v(hk)\n","      #for non rating cells (-1)- dont want to include (freeze)\n","      #will not update during gibbs sampling\n","      #keep -1 ratings (dont want to train on them)\n","      vk[v0<0] = v0[v0<0]\n","    #compute phk - sample h after k steps of contrastive divergence\n","    phk,_ = rbm.sample_h(vk)\n","    #train to update weights/bias\n","    rbm.train(v0, vk, ph0, phk)\n","    #loss = MAE of ratings for rated movies\n","    train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n","    #increment counter for loss calculation\n","    s += 1.\n","  print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch: 1 loss: tensor(0.3446)\n","epoch: 2 loss: tensor(0.2168)\n","epoch: 3 loss: tensor(0.2445)\n","epoch: 4 loss: tensor(0.2458)\n","epoch: 5 loss: tensor(0.2490)\n","epoch: 6 loss: tensor(0.2498)\n","epoch: 7 loss: tensor(0.2468)\n","epoch: 8 loss: tensor(0.2488)\n","epoch: 9 loss: tensor(0.2497)\n","epoch: 10 loss: tensor(0.2462)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Bak5uc8gd-gX"},"source":["## Testing the RBM\n"]},{"cell_type":"code","metadata":{"id":"5ztvzYRtiGCz","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1591629522828,"user_tz":-330,"elapsed":43623,"user":{"displayName":"Nirav Agarwal (RA1811003010570)","photoUrl":"","userId":"01096445040044781974"}},"outputId":"2b5ed305-7700-4e25-c59a-5adae77a603a"},"source":["#initialize loss, loss normalizer to 0\n","test_loss = 0\n","s = 0.\n","#for each user 1 by 1 (no batches)\n","for id_user in range(nb_users):\n","  #gets user from training set, test set\n","  #training set is input used to activate hidden neurons of RBM to predict neurons\n","    v = training_set[id_user:id_user+1]\n","    vt = test_set[id_user:id_user+1]\n","    #only need 1 step of walk for contrastive divergence\n","    #blind walk- trained by gibbs sampling (with random steps- MCMC)\n","    #if test user has rated movies\n","    if len(vt[vt>=0]) > 0:\n","      #get RBM predictions\n","        _,h = rbm.sample_h(v)\n","        _,v = rbm.sample_v(h)\n","        #calculate error\n","        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n","        s += 1.\n","print('test loss: '+str(test_loss/s))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test loss: tensor(0.2359)\n"],"name":"stdout"}]}]}